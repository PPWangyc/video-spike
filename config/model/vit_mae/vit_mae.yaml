model_class: ViT_MAE

hidden_size: 768
num_hidden_layers: 12
num_attention_heads: 12
intermediate_size: 3072
hidden_act: "gelu"
hidden_dropout_prob: 0.0
attention_probs_dropout_prob: 0.0
initializer_range: 0.02
layer_norm_eps: 1.e-12
image_size: 144 # usually 224
patch_size: 16
num_channels: 1 # 3 for RGB
qkv_bias: True
decoder_num_attention_heads: 16
decoder_hidden_size: 512
decoder_num_hidden_layers: 8
decoder_intermediate_size: 2048
mask_ratio: 0.75 # 0 for no masking, usually 0.75 (MAE)
norm_pix_loss: False

embed_size: 3 # projected embedding size, used for contrastive learning